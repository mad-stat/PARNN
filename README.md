# Probabilistic Autoregressive Neural Network (PARNN)

Usage of the repository for the paper "Probabilistic Autoregressive Neural Network Model for Time Series Forecasting [1]".

In this study, we propose a hybrid probabilistic autoregressive neural network (PARNN) model which is a generalization of the artificial neural network and recurrent neural network (RNN) model for irregular (non-stationary, nonlinear) time series forecasting. Our study considers publicly available real-world time series datatsets from different domains namely stock price [2], epidemics [3], energy [4], tourism [4], demography [4], and macroeconomics [5] to analyse the forecasting abiility of our proposed model.

* The training phase of the proposed PARNN model comprises of two stages. In the first phase the proposed model fits an autoregressive integrated moving average (ARIMA) model to the univariate time series based on the Akaike Information Criterion (AIC). The fitted model is then utilized to generate the residuals of the given series. 

* In the next training phase the residal series is modeled along with the original input time series using an auto-regressive neural network architecture having pre-defined lagged inputs from both residual and actual series and a single hidden layer to generate one-step ahead forecast. In the subsequent step, the neural network generates multi-step ahead forecasts iteratively and aggregates the corresponding forecasts to generate the final output. Graphical representation of the proposed PARNN model is provided below:
![Model_Img_mod](https://github.com/mad-stat/PARNN/blob/main/Models/Model.png)


* In this repository, we present application of the proposed PARNN model with 14 real-world time series datasets. These datasets are collected from varied domains and they demonstarte different characteristics. To evaluate the generalizability and scalability of the proposal we consider datasets with varied temporal unit and length.  The ".csv" files of these datasets available in [Source](https://github.com/mad-stat/PARNN/tree/main/Datasets)
  
* The [PARNN](https://github.com/mad-stat/PARNN/blob/main/Models/PARNN.R) file contains the source code and the implemntation of the proposed PARNN model. The proposed framework comprises of two hyper-parameters $(p,k,q)$, where $p$ denotes the number of lagged input observations of the original series, $q$ indicates the lagged observation of the residual series provided as input to the neural network, and $k$ indicates the number of nodes in the hidden layer of the proposed PARNN model. The hyper-parameters $p$ and $q are tuned by minimising the mean scaled absolue error (MASE) metric on the validation set. The suggested values of this hyper-parameter for different datasets are made available in the file [PARNN_Parameters](https://github.com/mad-stat/PARNN/blob/main/Models/Suggested%20hyper-parameter%20values%20of%20PARNN%20-%20Sheet1.csv) for different forecast horizons. The choice of the hyper-parameter $k$ is made as $k = \frac{(p+q+1)}{2}$ following [4].

* The application of different statistical and machine learning forecasting frameworks are available in [Forecasting_Models](https://github.com/mad-stat/PARNN/blob/main/Models/Statistical_Machine_Learning_Model_Implementation.R)[6-8]. Furthermore, deep learning forecasters are implemented using **darts**[9] library in Python, the [Deep Learning Forecast](https://github.com/mad-stat/PARNN/blob/main/Models/Deep_Learning_Models_Implementation.py) file contains the required implementations. These state-of-the-art forecasters were used to compare the efficacy of our proposed PARNN model.

* The forecasts generated by the three best performing models in the experimentation: proposed PARNN, TBATS, and ARNN models for selected real-world datasets considered in the study is digramatically represented as follows
![PARNN](https://github.com/mad-stat/PARNN/blob/main/Models/PARNN_Fit.png)

* Reults obtained in the paper for all the considered datasets can directly be computed along with the graphs and figures using the implementation files and datasets given in this repository for replicability and sake of reproducibility of our paper. 

## Citing Our Work
Panja, Madhurima; Chakraborty, Tanujit; Kumar, Uttam and Hadid, Abdenour.\
"Probabilistic Autoregressive Neural Network Model for Time Series Forecasting."\
arXiv preprint arXiv:2204.09640 (2022).

@article{panja2022probabilistic,\
  title={Probabilistic Autoregressive Neural Network Model for Time Series Forecasting},\
  author={Panja, Madhurima; Chakraborty, Tanujit; Kumar, Uttam and Hadid, Abdenour},\
  journal={arXiv preprint arXiv:2204.09640},\
  year={2022},\
  note=https://arxiv.org/pdf/2204.09640.pdf ,\
}

## References
* <a id="1">[1]</a> [Probabilistic Autoregressive Neural Network Model for Time Series Forecasting](https://arxiv.org/pdf/2204.09640.pdf)
* <a id="2">[2]</a> [Yahoo Finance](https://finance.yahoo.com/)
* <a id="3">[3]</a> [Disease_outbreak_data](https://github.com/JohannHM/Disease-Outbreaks-Data)
* <a id="4">[4]</a> [Forecasting: Principles and Practice](https://otexts.com/fpp3/)
* <a id="5">[5]</a> [FRED Economic Data](https://fred.stlouisfed.org/)
* <a id="6">[6]</a> Hyndman, Rob J., and Yeasmin Khandakar. "Automatic time series forecasting: the forecast package for R." Journal of statistical software 27 (2008): 1-22.
* <a id="7">[7]</a> Di Narzo, A. F., Aznarte, J. L., & Stigler, M. (2022). Package ‘tsDyn’.
* <a id="8">[8]</a> Paul, Ranjit Kumar, et al. "Package ‘waveletarima’." Seed 500 (2017): 1-5.

* <a id="9">[9]</a> Herzen, Julien, et al. "Darts: User-friendly modern machine learning for time series." Journal of Machine Learning Research 23.124 (2022): 1-6.
